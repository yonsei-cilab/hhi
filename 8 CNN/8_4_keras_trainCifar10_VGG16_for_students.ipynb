{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_keras_trainCifar10_VGG16_for_students.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p4-0ijKFgAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "#*****************************************************\n",
        "#               Standard\n",
        "#*****************************************************\n",
        "\n",
        "\n",
        "name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "num_classes = 10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "(datanum, h, w, channum) = x_train.shape\n",
        "(_, outputdim) = y_train.shape\n",
        "\n",
        "\n",
        "\n",
        "#Visualizing CIFAR 10\n",
        "fig = plt.figure()\n",
        "ims = np.random.randint(datanum, size=15)\n",
        "\n",
        "for i in range(15):\n",
        "    subplot = fig.add_subplot(3,5, i+1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    subplot.set_title(\"%s\" %name_list[np.argmax(y_train[ims[i]])])\n",
        "    subplot.imshow(x_train[ims[i],:,:,:])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ********************************************************\n",
        "#               Training\n",
        "# ********************************************************\n",
        "\n",
        "# Training Parameters\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "# *************************************************************\n",
        "#               Model building\n",
        "# *************************************************************\n",
        "vggcfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n",
        "}\n",
        "\n",
        "\n",
        "def build_network(vggname):\n",
        "    cfg = vggcfg[vggname]\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(h, w, channum)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Feature\n",
        "    for x in cfg[1:]:\n",
        "        if x == 'M':\n",
        "            model.add(layers.MaxPooling2D((2, 2)))\n",
        "        else:\n",
        "            model.add(layers.Conv2D(x, (3, 3), padding='same', activation='relu'))\n",
        "            model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    # ***********************************\n",
        "    #\n",
        "    #     Fill in the blank\n",
        "    #\n",
        "    # ***********************************\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build_network('VGG19')\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # randomly shift images horizontally (fraction of total width)\n",
        "    width_shift_range=0.1,\n",
        "    # randomly shift images vertically (fraction of total height)\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.,  # set range for random shear\n",
        "    zoom_range=0.,  # set range for random zoom\n",
        "    channel_shift_range=0.,  # set range for random channel shifts\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,  # value used for fill_mode = \"constant\"\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,  # randomly flip images\n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=None,\n",
        "    # set function that will be applied on each input\n",
        "    preprocessing_function=None,\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\n",
        "    data_format=None,\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "    validation_split=0.0)\n",
        "\n",
        "# Compute quantities required for feature-wise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# learning rate schedule\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.1\n",
        "    epochs_drop = 30.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "# learning schedule callback\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5, min_lr=0.0)\n",
        "callbacks_list = [reduce_lr]\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size), epochs=epochs, validation_data=(x_test, y_test),\n",
        "                              callbacks=callbacks_list, shuffle=True, verbose=2, workers=1)\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nL6-_oJctiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *************************************************************\n",
        "#               Visualization\n",
        "# *************************************************************\n",
        "\n",
        "# Training loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Training accuracy\n",
        "plt.clf()   # 그래프를 초기화합니다\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5gx31IIMHvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as skl\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    num_classes = 10\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    print(x_train.shape[1], 'train samples')\n",
        "    print(x_test.shape[2], 'test samples')\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # Convert class vectors to binary class matrices.\n",
        "    y_train = utils.to_categorical(y_train, num_classes)\n",
        "    y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    (_, outputdim) = y_test.shape\n",
        "\n",
        "\n",
        "\n",
        "    #Score trained model.\n",
        "    scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "    print('Test loss:', scores[0])\n",
        "    print('Test accuracy:', scores[1])\n",
        "\n",
        "    target = y_test\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "    ylabel = np.argmax(target,axis=1)\n",
        "    yhatlabel = np.argmax(pred,axis=1)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cnf_matrix = skl.confusion_matrix(ylabel, yhatlabel)\n",
        "    np.set_printoptions(precision=2)\n",
        "    is_correct = (ylabel == yhatlabel)\n",
        "    acc = np.sum(is_correct * 1) / len(is_correct)\n",
        "    print('accuracy:%.5f' %acc)\n",
        "\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cnf_matrix, classes=name_list,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "    # Plot normalized confusion matrix\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cnf_matrix, classes=name_list, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}