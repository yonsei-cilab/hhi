{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9 GAN_MNIST_for_student.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLXZCN0UcPfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras import backend as K\n",
        " \n",
        "\n",
        "# learning rate schedule\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.0004\n",
        "    drop = 0.5\n",
        "    epochs_drop = 5.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 50\n",
        "input_dim = 100\n",
        "sample_size = 6\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') - 127.5\n",
        "x_test = x_test.astype('float32') - 127.5\n",
        "x_train /= 127.5\n",
        "x_test /= 127.5\n",
        "x_train = np.expand_dims(x_train, axis=-1)  # --> [6000,28,28,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4rL-R3_cYSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# ************************************\n",
        "#          discriminator\n",
        "# ************************************\n",
        "discriminator = models.Sequential()\n",
        "discriminator.add(layers.Conv2D(64, (5, 5), padding='same', activation='tanh',\n",
        "                                input_shape=(28, 28,1)))\n",
        "discriminator.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "discriminator.add(layers.Conv2D(128, (5, 5), padding='same', activation='tanh'))\n",
        "discriminator.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "discriminator.add(layers.Flatten())\n",
        "discriminator.add(layers.Dense(1024, activation='tanh'))\n",
        "discriminator.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt_D = optimizers.RMSprop(lr=0.0004, clipvalue=1.0)\n",
        "discriminator.trainable = True\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=opt_D)\n",
        "discriminator.summary()\n",
        "\n",
        "\n",
        "\n",
        "# ************************************\n",
        "#          generator\n",
        "# ************************************\n",
        "generator = models.Sequential()\n",
        "generator.add(layers.Dense(1024, activation='tanh', input_dim=input_dim))\n",
        "generator.add(layers.Dense(128 * 7 * 7, activation='tanh'))\n",
        "generator.add(layers.BatchNormalization())\n",
        "generator.add(layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,)))\n",
        "generator.add(layers.UpSampling2D(size=(2, 2)))\n",
        "generator.add(layers.Conv2D(64, (5, 5), padding='same', activation='tanh'))\n",
        "generator.add(layers.UpSampling2D(size=(2, 2)))\n",
        "generator.add(layers.Conv2D(1, (5, 5), padding='same', activation='tanh'))\n",
        "generator.summary()\n",
        "\n",
        "\n",
        "# ************************************\n",
        "#      gan = generator + discriminator\n",
        "# ************************************\n",
        "gan = models.Sequential()\n",
        "    # ***********************************\n",
        "    #\n",
        "    #     Fill in the blank\n",
        "    #\n",
        "    # ***********************************\n",
        "opt_G = optimizers.RMSprop(lr=0.0004, clipvalue=1.0)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=opt_G)\n",
        "gan.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9K6da0Jc7lG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    for index in range(int(x_train.shape[0] / batch_size)):\n",
        "\n",
        "        # Distriminator training on the batch\n",
        "        x = x_train[index * batch_size:(index + 1) * batch_size]\n",
        "        ln = x.shape[0]\n",
        "        z = np.random.uniform(-1.0, 1.0, (ln, input_dim))\n",
        "        gen = generator.predict(z, verbose=0)\n",
        "        input_D = np.concatenate((x, gen))\n",
        "        y_D = np.array([1.] * ln + [0.] * ln)\n",
        "        y_D += 0.01 * np.random.random(y_D.shape)\n",
        "        discriminator.trainable = True\n",
        "        current_learning_rate = step_decay(epoch)\n",
        "        K.set_value(discriminator.optimizer.lr, current_learning_rate)\n",
        "        loss_D = discriminator.train_on_batch(input_D, y_D)\n",
        "\n",
        "        # generator training on the batch\n",
        "        z = np.random.uniform(-1.0, 1.0, (ln, input_dim))\n",
        "        discriminator.trainable = False\n",
        "        K.set_value(gan.optimizer.lr, current_learning_rate)\n",
        "        loss_G = gan.train_on_batch(z, np.array([1] * ln))\n",
        "\n",
        "\n",
        "    print('Epoch = %d, Loss D:%f,  Loss G:%f' %(epoch, loss_D, loss_G))\n",
        "\n",
        "\n",
        "    if epoch % 5 == 0 or epoch == epochs - 1:\n",
        "        z = np.random.uniform(-1.0, 1.0, (ln, input_dim))\n",
        "        gen = gan.layers[0].predict(z, verbose=0)\n",
        "\n",
        "        fig = plt.figure(figsize=(20, 2))\n",
        "        fig.suptitle(\"Epoch = %d\" % epoch)\n",
        "        for i in range(sample_size):\n",
        "            plt.subplot(1, sample_size, i + 1)\n",
        "            plt.imshow(gen[i].reshape((28, 28)))\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}